# üóÑÔ∏è Advanced Database Concepts & Optimization

## Table of Contents
1. [Database Internals](#database-internals/)
2. [Query Optimization](#query-optimization/)
3. [Indexing Strategies](#indexing-strategies/)
4. [Transaction Management](#transaction-management/)
5. [Concurrency Control](#concurrency-control/)
6. [Database Sharding](#database-sharding/)
7. [Replication Strategies](#replication-strategies/)
8. [Performance Tuning](#performance-tuning/)
9. [Go Implementation Examples](#go-implementation-examples/)
10. [Interview Questions](#interview-questions/)

## Database Internals

### Storage Engine Architecture

```go
package main

import (
    "fmt"
    "os"
    "sync"
)

// B+ Tree Node for Database Index
type BPlusTreeNode struct {
    isLeaf     bool
    keys       []int
    values     []interface{}
    children   []*BPlusTreeNode
    parent     *BPlusTreeNode
    next       *BPlusTreeNode // For leaf nodes
    prev       *BPlusTreeNode // For leaf nodes
}

type BPlusTree struct {
    root   *BPlusTreeNode
    degree int
    mutex  sync.RWMutex
}

func NewBPlusTree(degree int) *BPlusTree {
    return &BPlusTree{
        root:   &BPlusTreeNode{isLeaf: true, keys: make([]int, 0)},
        degree: degree,
    }
}

func (t *BPlusTree) Insert(key int, value interface{}) {
    t.mutex.Lock()
    defer t.mutex.Unlock()
    
    if t.root == nil {
        t.root = &BPlusTreeNode{
            isLeaf: true,
            keys:   []int{key},
            values: []interface{}{value},
        }
        return
    }
    
    // Find the leaf node to insert into
    leaf := t.findLeaf(key)
    
    // Insert into leaf node
    if len(leaf.keys) < t.degree-1 {
        t.insertIntoLeaf(leaf, key, value)
    } else {
        t.splitAndInsert(leaf, key, value)
    }
}

func (t *BPlusTree) findLeaf(key int) *BPlusTreeNode {
    current := t.root
    
    for !current.isLeaf {
        i := 0
        for i < len(current.keys) && key >= current.keys[i] {
            i++
        }
        current = current.children[i]
    }
    
    return current
}

func (t *BPlusTree) insertIntoLeaf(leaf *BPlusTreeNode, key int, value interface{}) {
    i := 0
    for i < len(leaf.keys) && key > leaf.keys[i] {
        i++
    }
    
    // Insert key and value at position i
    leaf.keys = append(leaf.keys[:i], append([]int{key}, leaf.keys[i:]...)...)
    leaf.values = append(leaf.values[:i], append([]interface{}{value}, leaf.values[i:]...)...)
}

func (t *BPlusTree) splitAndInsert(leaf *BPlusTreeNode, key int, value interface{}) {
    // Create new leaf node
    newLeaf := &BPlusTreeNode{
        isLeaf: true,
        keys:   make([]int, 0),
        values: make([]interface{}, 0),
    }
    
    // Split keys and values
    mid := t.degree / 2
    newLeaf.keys = append(newLeaf.keys, leaf.keys[mid:]...)
    newLeaf.values = append(newLeaf.values, leaf.values[mid:]...)
    leaf.keys = leaf.keys[:mid]
    leaf.values = leaf.values[:mid]
    
    // Insert new key
    if key < newLeaf.keys[0] {
        t.insertIntoLeaf(leaf, key, value)
    } else {
        t.insertIntoLeaf(newLeaf, key, value)
    }
    
    // Update parent
    t.updateParent(leaf, newLeaf)
}

func (t *BPlusTree) updateParent(left, right *BPlusTreeNode) {
    // Implementation for updating parent nodes
    // This is a simplified version
}

func (t *BPlusTree) Search(key int) interface{} {
    t.mutex.RLock()
    defer t.mutex.RUnlock()
    
    leaf := t.findLeaf(key)
    
    for i, k := range leaf.keys {
        if k == key {
            return leaf.values[i]
        }
    }
    
    return nil
}

// WAL (Write-Ahead Log) Implementation
type WALEntry struct {
    LSN     int64  // Log Sequence Number
    Type    string // INSERT, UPDATE, DELETE
    Table   string
    Key     string
    Value   []byte
    Timestamp int64
}

type WAL struct {
    entries []WALEntry
    mutex   sync.RWMutex
    nextLSN int64
}

func NewWAL() *WAL {
    return &WAL{
        entries: make([]WALEntry, 0),
        nextLSN: 1,
    }
}

func (w *WAL) Append(entryType, table, key string, value []byte) {
    w.mutex.Lock()
    defer w.mutex.Unlock()
    
    entry := WALEntry{
        LSN:       w.nextLSN,
        Type:      entryType,
        Table:     table,
        Key:       key,
        Value:     value,
        Timestamp: time.Now().UnixNano(),
    }
    
    w.entries = append(w.entries, entry)
    w.nextLSN++
}

func (w *WAL) GetEntries(fromLSN int64) []WALEntry {
    w.mutex.RLock()
    defer w.mutex.RUnlock()
    
    var result []WALEntry
    for _, entry := range w.entries {
        if entry.LSN >= fromLSN {
            result = append(result, entry)
        }
    }
    
    return result
}

func (w *WAL) Truncate(toLSN int64) {
    w.mutex.Lock()
    defer w.mutex.Unlock()
    
    var newEntries []WALEntry
    for _, entry := range w.entries {
        if entry.LSN > toLSN {
            newEntries = append(newEntries, entry)
        }
    }
    
    w.entries = newEntries
}
```

### Buffer Pool Management

```go
package main

import (
    "container/list"
    "fmt"
    "sync"
)

type Page struct {
    PageID    int
    Data      []byte
    IsDirty   bool
    PinCount  int
    LastUsed  int64
}

type BufferPool struct {
    pages     map[int]*Page
    lruList   *list.List
    capacity  int
    mutex     sync.RWMutex
    hitCount  int64
    missCount int64
}

func NewBufferPool(capacity int) *BufferPool {
    return &BufferPool{
        pages:    make(map[int]*Page),
        lruList:  list.New(),
        capacity: capacity,
    }
}

func (bp *BufferPool) GetPage(pageID int) (*Page, error) {
    bp.mutex.Lock()
    defer bp.mutex.Unlock()
    
    if page, exists := bp.pages[pageID]; exists {
        // Page is in buffer pool
        bp.hitCount++
        page.PinCount++
        bp.moveToFront(page)
        return page, nil
    }
    
    // Page not in buffer pool
    bp.missCount++
    
    // Load page from disk
    page, err := bp.loadPageFromDisk(pageID)
    if err != nil {
        return nil, err
    }
    
    // Add to buffer pool
    bp.addToBufferPool(page)
    
    return page, nil
}

func (bp *BufferPool) loadPageFromDisk(pageID int) (*Page, error) {
    // Simulate loading from disk
    return &Page{
        PageID:   pageID,
        Data:     make([]byte, 4096), // 4KB page
        IsDirty:  false,
        PinCount: 1,
        LastUsed: time.Now().UnixNano(),
    }, nil
}

func (bp *BufferPool) addToBufferPool(page *Page) {
    if len(bp.pages) >= bp.capacity {
        bp.evictPage()
    }
    
    bp.pages[page.PageID] = page
    bp.lruList.PushFront(page)
}

func (bp *BufferPool) evictPage() {
    // Find page to evict (LRU)
    for e := bp.lruList.Back(); e != nil; e = e.Prev() {
        page := e.Value.(*Page)
        if page.PinCount == 0 {
            // Can evict this page
            if page.IsDirty {
                bp.flushPageToDisk(page)
            }
            
            delete(bp.pages, page.PageID)
            bp.lruList.Remove(e)
            break
        }
    }
}

func (bp *BufferPool) moveToFront(page *Page) {
    // Move page to front of LRU list
    for e := bp.lruList.Front(); e != nil; e = e.Next() {
        if e.Value.(*Page) == page {
            bp.lruList.MoveToFront(e)
            break
        }
    }
}

func (bp *BufferPool) flushPageToDisk(page *Page) {
    // Simulate flushing to disk
    fmt.Printf("Flushing page %d to disk\n", page.PageID)
}

func (bp *BufferPool) GetHitRatio() float64 {
    bp.mutex.RLock()
    defer bp.mutex.RUnlock()
    
    total := bp.hitCount + bp.missCount
    if total == 0 {
        return 0
    }
    
    return float64(bp.hitCount) / float64(total)
}
```

## Query Optimization

### Query Planner and Optimizer

```go
package main

import (
    "fmt"
    "sort"
    "strings"
)

type QueryPlan struct {
    Root     *PlanNode
    Cost     float64
    Cardinality int
}

type PlanNode struct {
    Type         string
    Table        string
    Index        string
    Condition    string
    Children     []*PlanNode
    Cost         float64
    Cardinality  int
    Selectivity  float64
}

type QueryOptimizer struct {
    statistics map[string]*TableStats
}

type TableStats struct {
    RowCount      int
    ColumnStats   map[string]*ColumnStats
    IndexStats    map[string]*IndexStats
}

type ColumnStats struct {
    DistinctCount int
    MinValue      interface{}
    MaxValue      interface{}
    NullCount     int
}

type IndexStats struct {
    Cardinality int
    Height      int
    Pages       int
}

func NewQueryOptimizer() *QueryOptimizer {
    return &QueryOptimizer{
        statistics: make(map[string]*TableStats),
    }
}

func (qo *QueryOptimizer) OptimizeQuery(query string) *QueryPlan {
    // Parse query (simplified)
    parsed := qo.parseQuery(query)
    
    // Generate possible plans
    plans := qo.generatePlans(parsed)
    
    // Choose best plan based on cost
    bestPlan := qo.chooseBestPlan(plans)
    
    return bestPlan
}

func (qo *QueryOptimizer) parseQuery(query string) *ParsedQuery {
    // Simplified query parsing
    return &ParsedQuery{
        Tables:     []string{"users", "orders"},
        Conditions: []string{"users.id = orders.user_id", "users.age > 25"},
        Columns:    []string{"users.name", "orders.total"},
    }
}

type ParsedQuery struct {
    Tables     []string
    Conditions []string
    Columns    []string
}

func (qo *QueryOptimizer) generatePlans(parsed *ParsedQuery) []*QueryPlan {
    var plans []*QueryPlan
    
    // Generate different join orders
    for _, joinOrder := range qo.generateJoinOrders(parsed.Tables) {
        plan := qo.buildPlan(joinOrder, parsed)
        plans = append(plans, plan)
    }
    
    return plans
}

func (qo *QueryOptimizer) generateJoinOrders(tables []string) [][]string {
    // Generate all possible join orders
    var orders [][]string
    
    // Simple permutation (in practice, use more sophisticated algorithms)
    for i := 0; i < len(tables); i++ {
        for j := i + 1; j < len(tables); j++ {
            order := []string{tables[i], tables[j]}
            orders = append(orders, order)
        }
    }
    
    return orders
}

func (qo *QueryOptimizer) buildPlan(joinOrder []string, parsed *ParsedQuery) *QueryPlan {
    var root *PlanNode
    
    for i, table := range joinOrder {
        node := &PlanNode{
            Type: "TableScan",
            Table: table,
        }
        
        // Apply filters
        node = qo.applyFilters(node, parsed.Conditions)
        
        // Choose index
        node = qo.chooseIndex(node)
        
        if root == nil {
            root = node
        } else {
            // Create join node
            joinNode := &PlanNode{
                Type:     "HashJoin",
                Children: []*PlanNode{root, node},
            }
            root = joinNode
        }
    }
    
    // Calculate cost and cardinality
    cost := qo.calculateCost(root)
    cardinality := qo.calculateCardinality(root)
    
    return &QueryPlan{
        Root:        root,
        Cost:        cost,
        Cardinality: cardinality,
    }
}

func (qo *QueryOptimizer) applyFilters(node *PlanNode, conditions []string) *PlanNode {
    // Apply relevant filters to the node
    for _, condition := range conditions {
        if strings.Contains(condition, node.Table) {
            node.Condition = condition
            break
        }
    }
    
    return node
}

func (qo *QueryOptimizer) chooseIndex(node *PlanNode) *PlanNode {
    // Choose best index for the table and condition
    stats := qo.statistics[node.Table]
    if stats == nil {
        return node
    }
    
    bestIndex := ""
    bestCost := float64(1e9)
    
    for indexName, indexStats := range stats.IndexStats {
        cost := qo.calculateIndexCost(indexStats, node.Condition)
        if cost < bestCost {
            bestCost = cost
            bestIndex = indexName
        }
    }
    
    if bestIndex != "" {
        node.Index = bestIndex
        node.Type = "IndexScan"
    }
    
    return node
}

func (qo *QueryOptimizer) calculateIndexCost(indexStats *IndexStats, condition string) float64 {
    // Simplified cost calculation
    baseCost := float64(indexStats.Height) * 0.1
    selectivity := qo.estimateSelectivity(condition)
    return baseCost + float64(indexStats.Cardinality) * selectivity
}

func (qo *QueryOptimizer) estimateSelectivity(condition string) float64 {
    // Simplified selectivity estimation
    if strings.Contains(condition, "=") {
        return 0.1 // 10% selectivity for equality
    } else if strings.Contains(condition, ">") || strings.Contains(condition, "<") {
        return 0.3 // 30% selectivity for range
    }
    return 0.5 // 50% default
}

func (qo *QueryOptimizer) calculateCost(node *PlanNode) float64 {
    if node == nil {
        return 0
    }
    
    cost := node.Cost
    for _, child := range node.Children {
        cost += qo.calculateCost(child)
    }
    
    return cost
}

func (qo *QueryOptimizer) calculateCardinality(node *PlanNode) int {
    if node == nil {
        return 0
    }
    
    if len(node.Children) == 0 {
        return node.Cardinality
    }
    
    // Calculate join cardinality
    leftCard := qo.calculateCardinality(node.Children[0])
    rightCard := qo.calculateCardinality(node.Children[1])
    
    return leftCard * rightCard / 100 // Simplified
}

func (qo *QueryOptimizer) chooseBestPlan(plans []*QueryPlan) *QueryPlan {
    if len(plans) == 0 {
        return nil
    }
    
    bestPlan := plans[0]
    for _, plan := range plans[1:] {
        if plan.Cost < bestPlan.Cost {
            bestPlan = plan
        }
    }
    
    return bestPlan
}
```

## Indexing Strategies

### Advanced Index Types

```go
package main

import (
    "fmt"
    "sort"
    "strings"
)

// Composite Index
type CompositeIndex struct {
    columns []string
    entries map[string][]int // key -> row IDs
}

func NewCompositeIndex(columns []string) *CompositeIndex {
    return &CompositeIndex{
        columns: columns,
        entries: make(map[string][]int),
    }
}

func (ci *CompositeIndex) Insert(values []interface{}, rowID int) {
    key := ci.buildKey(values)
    ci.entries[key] = append(ci.entries[key], rowID)
}

func (ci *CompositeIndex) Search(conditions map[string]interface{}) []int {
    var result []int
    
    for key, rowIDs := range ci.entries {
        if ci.matches(key, conditions) {
            result = append(result, rowIDs...)
        }
    }
    
    return result
}

func (ci *CompositeIndex) buildKey(values []interface{}) string {
    var parts []string
    for _, value := range values {
        parts = append(parts, fmt.Sprintf("%v", value))
    }
    return strings.Join(parts, "|")
}

func (ci *CompositeIndex) matches(key string, conditions map[string]interface{}) bool {
    parts := strings.Split(key, "|")
    
    for i, column := range ci.columns {
        if expected, exists := conditions[column]; exists {
            if fmt.Sprintf("%v", expected) != parts[i] {
                return false
            }
        }
    }
    
    return true
}

// Partial Index
type PartialIndex struct {
    condition string
    entries   map[string][]int
}

func NewPartialIndex(condition string) *PartialIndex {
    return &PartialIndex{
        condition: condition,
        entries:   make(map[string][]int),
    }
}

func (pi *PartialIndex) Insert(key string, rowID int, row map[string]interface{}) {
    if pi.evaluateCondition(row) {
        pi.entries[key] = append(pi.entries[key], rowID)
    }
}

func (pi *PartialIndex) evaluateCondition(row map[string]interface{}) bool {
    // Simplified condition evaluation
    // In practice, this would be a proper expression evaluator
    return true
}

// Covering Index
type CoveringIndex struct {
    columns []string
    entries map[string]*CoveringEntry
}

type CoveringEntry struct {
    RowID int
    Data  map[string]interface{}
}

func NewCoveringIndex(columns []string) *CoveringIndex {
    return &CoveringIndex{
        columns: columns,
        entries: make(map[string]*CoveringEntry),
    }
}

func (ci *CoveringIndex) Insert(key string, rowID int, data map[string]interface{}) {
    ci.entries[key] = &CoveringEntry{
        RowID: rowID,
        Data:  data,
    }
}

func (ci *CoveringIndex) Get(key string) *CoveringEntry {
    return ci.entries[key]
}

// Bitmap Index
type BitmapIndex struct {
    column string
    bitmaps map[interface{}]*Bitmap
}

type Bitmap struct {
    bits []uint64
    size int
}

func NewBitmap(size int) *Bitmap {
    return &Bitmap{
        bits: make([]uint64, (size+63)/64),
        size: size,
    }
}

func (b *Bitmap) Set(pos int) {
    if pos >= 0 && pos < b.size {
        b.bits[pos/64] |= 1 << (pos % 64)
    }
}

func (b *Bitmap) Get(pos int) bool {
    if pos >= 0 && pos < b.size {
        return (b.bits[pos/64] & (1 << (pos % 64))) != 0
    }
    return false
}

func (b *Bitmap) And(other *Bitmap) *Bitmap {
    result := NewBitmap(b.size)
    for i := 0; i < len(b.bits); i++ {
        result.bits[i] = b.bits[i] & other.bits[i]
    }
    return result
}

func (b *Bitmap) Or(other *Bitmap) *Bitmap {
    result := NewBitmap(b.size)
    for i := 0; i < len(b.bits); i++ {
        result.bits[i] = b.bits[i] | other.bits[i]
    }
    return result
}

func NewBitmapIndex(column string, size int) *BitmapIndex {
    return &BitmapIndex{
        column:  column,
        bitmaps: make(map[interface{}]*Bitmap),
    }
}

func (bi *BitmapIndex) Insert(value interface{}, rowID int) {
    if bi.bitmaps[value] == nil {
        bi.bitmaps[value] = NewBitmap(1000) // Simplified size
    }
    bi.bitmaps[value].Set(rowID)
}

func (bi *BitmapIndex) Search(value interface{}) *Bitmap {
    return bi.bitmaps[value]
}

func (bi *BitmapIndex) SearchRange(min, max interface{}) *Bitmap {
    result := NewBitmap(1000)
    
    for value, bitmap := range bi.bitmaps {
        if bi.inRange(value, min, max) {
            result = result.Or(bitmap)
        }
    }
    
    return result
}

func (bi *BitmapIndex) inRange(value, min, max interface{}) bool {
    // Simplified range check
    return true
}
```

## Transaction Management

### ACID Properties Implementation

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

type Transaction struct {
    ID        int
    StartTime time.Time
    State     TransactionState
    Locks     map[string]LockType
    Log       []LogEntry
}

type TransactionState int

const (
    ACTIVE TransactionState = iota
    COMMITTED
    ABORTED
)

type LockType int

const (
    SHARED LockType = iota
    EXCLUSIVE
)

type LogEntry struct {
    LSN       int64
    Timestamp time.Time
    Type      string
    Data      interface{}
}

type LockManager struct {
    locks map[string]*Lock
    mutex sync.RWMutex
}

type Lock struct {
    Resource   string
    Type       LockType
    Holders    map[int]bool
    Waiters    []int
    mutex      sync.Mutex
}

func NewLockManager() *LockManager {
    return &LockManager{
        locks: make(map[string]*Lock),
    }
}

func (lm *LockManager) AcquireLock(txnID int, resource string, lockType LockType) bool {
    lm.mutex.Lock()
    defer lm.mutex.Unlock()
    
    lock, exists := lm.locks[resource]
    if !exists {
        lock = &Lock{
            Resource: resource,
            Type:     lockType,
            Holders:  make(map[int]bool),
            Waiters:  make([]int, 0),
        }
        lm.locks[resource] = lock
    }
    
    lock.mutex.Lock()
    defer lock.mutex.Unlock()
    
    // Check if lock can be acquired
    if lm.canAcquireLock(lock, txnID, lockType) {
        lock.Holders[txnID] = true
        if lockType == EXCLUSIVE {
            lock.Type = EXCLUSIVE
        }
        return true
    }
    
    // Add to waiters
    lock.Waiters = append(lock.Waiters, txnID)
    return false
}

func (lm *LockManager) canAcquireLock(lock *Lock, txnID int, lockType LockType) bool {
    // If no holders, can acquire
    if len(lock.Holders) == 0 {
        return true
    }
    
    // If already holding the lock
    if lock.Holders[txnID] {
        return true
    }
    
    // If requesting shared lock and current is shared
    if lockType == SHARED && lock.Type == SHARED {
        return true
    }
    
    // Otherwise, cannot acquire
    return false
}

func (lm *LockManager) ReleaseLock(txnID int, resource string) {
    lm.mutex.Lock()
    defer lm.mutex.Unlock()
    
    lock, exists := lm.locks[resource]
    if !exists {
        return
    }
    
    lock.mutex.Lock()
    defer lock.mutex.Unlock()
    
    delete(lock.Holders, txnID)
    
    // Process waiters
    if len(lock.Waiters) > 0 {
        waiter := lock.Waiters[0]
        lock.Waiters = lock.Waiters[1:]
        lock.Holders[waiter] = true
    }
}

// Two-Phase Locking Protocol
type TwoPhaseLocking struct {
    lockManager *LockManager
    transactions map[int]*Transaction
    mutex       sync.RWMutex
}

func NewTwoPhaseLocking() *TwoPhaseLocking {
    return &TwoPhaseLocking{
        lockManager:  NewLockManager(),
        transactions: make(map[int]*Transaction),
    }
}

func (tpl *TwoPhaseLocking) BeginTransaction() int {
    tpl.mutex.Lock()
    defer tpl.mutex.Unlock()
    
    txnID := len(tpl.transactions) + 1
    txn := &Transaction{
        ID:        txnID,
        StartTime: time.Now(),
        State:     ACTIVE,
        Locks:     make(map[string]LockType),
        Log:       make([]LogEntry, 0),
    }
    
    tpl.transactions[txnID] = txn
    return txnID
}

func (tpl *TwoPhaseLocking) Read(txnID int, resource string) (interface{}, error) {
    tpl.mutex.RLock()
    txn, exists := tpl.transactions[txnID]
    tpl.mutex.RUnlock()
    
    if !exists || txn.State != ACTIVE {
        return nil, fmt.Errorf("transaction not active")
    }
    
    // Acquire shared lock
    if !tpl.lockManager.AcquireLock(txnID, resource, SHARED) {
        return nil, fmt.Errorf("could not acquire shared lock")
    }
    
    txn.Locks[resource] = SHARED
    
    // Log the read
    txn.Log = append(txn.Log, LogEntry{
        LSN:       int64(len(txn.Log) + 1),
        Timestamp: time.Now(),
        Type:      "READ",
        Data:      resource,
    })
    
    // Simulate read operation
    return fmt.Sprintf("data from %s", resource), nil
}

func (tpl *TwoPhaseLocking) Write(txnID int, resource string, data interface{}) error {
    tpl.mutex.RLock()
    txn, exists := tpl.transactions[txnID]
    tpl.mutex.RUnlock()
    
    if !exists || txn.State != ACTIVE {
        return fmt.Errorf("transaction not active")
    }
    
    // Acquire exclusive lock
    if !tpl.lockManager.AcquireLock(txnID, resource, EXCLUSIVE) {
        return fmt.Errorf("could not acquire exclusive lock")
    }
    
    txn.Locks[resource] = EXCLUSIVE
    
    // Log the write
    txn.Log = append(txn.Log, LogEntry{
        LSN:       int64(len(txn.Log) + 1),
        Timestamp: time.Now(),
        Type:      "WRITE",
        Data:      map[string]interface{}{"resource": resource, "data": data},
    })
    
    return nil
}

func (tpl *TwoPhaseLocking) Commit(txnID int) error {
    tpl.mutex.Lock()
    defer tpl.mutex.Unlock()
    
    txn, exists := tpl.transactions[txnID]
    if !exists || txn.State != ACTIVE {
        return fmt.Errorf("transaction not active")
    }
    
    // Phase 1: Prepare (all locks acquired)
    // Phase 2: Commit (release all locks)
    
    for resource := range txn.Locks {
        tpl.lockManager.ReleaseLock(txnID, resource)
    }
    
    txn.State = COMMITTED
    
    // Log commit
    txn.Log = append(txn.Log, LogEntry{
        LSN:       int64(len(txn.Log) + 1),
        Timestamp: time.Now(),
        Type:      "COMMIT",
        Data:      nil,
    })
    
    return nil
}

func (tpl *TwoPhaseLocking) Abort(txnID int) error {
    tpl.mutex.Lock()
    defer tpl.mutex.Unlock()
    
    txn, exists := tpl.transactions[txnID]
    if !exists || txn.State != ACTIVE {
        return fmt.Errorf("transaction not active")
    }
    
    // Release all locks
    for resource := range txn.Locks {
        tpl.lockManager.ReleaseLock(txnID, resource)
    }
    
    txn.State = ABORTED
    
    // Log abort
    txn.Log = append(txn.Log, LogEntry{
        LSN:       int64(len(txn.Log) + 1),
        Timestamp: time.Now(),
        Type:      "ABORT",
        Data:      nil,
    })
    
    return nil
}
```

## Interview Questions

### Basic Concepts
1. **What are the different types of database indexes?**
2. **Explain the difference between B-tree and B+ tree.**
3. **How does query optimization work?**
4. **What are the ACID properties?**
5. **Explain different concurrency control mechanisms.**

### Advanced Topics
1. **How would you implement a database buffer pool?**
2. **Explain the two-phase locking protocol.**
3. **How do you handle deadlocks in database systems?**
4. **What is the difference between optimistic and pessimistic concurrency control?**
5. **How would you implement database sharding?**

### System Design
1. **Design a distributed database system.**
2. **How would you implement database replication?**
3. **Design a query optimization engine.**
4. **How would you implement a distributed transaction system?**
5. **Design a database backup and recovery system.**

## Conclusion

Advanced database concepts are essential for building scalable, high-performance systems. Key areas to master:

- **Database Internals**: Storage engines, buffer management, WAL
- **Query Optimization**: Cost-based optimization, statistics
- **Indexing**: Various index types and their use cases
- **Transaction Management**: ACID properties, concurrency control
- **Performance Tuning**: Monitoring, profiling, optimization
- **Distributed Systems**: Sharding, replication, consistency

Understanding these concepts helps in:
- Designing efficient database schemas
- Optimizing query performance
- Building scalable systems
- Troubleshooting performance issues
- Preparing for technical interviews

This guide provides a comprehensive foundation for advanced database concepts and their practical implementation in Go.
